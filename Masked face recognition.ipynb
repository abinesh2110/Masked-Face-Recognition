{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b246af8-5530-4b56-ab34-9a6ff2f57efa",
   "metadata": {},
   "source": [
    "REQUIRED LIBRARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae7dd1-3306-417a-8e55-25dfe5b57244",
   "metadata": {},
   "source": [
    "LOADING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041537f-8bcd-46d0-9869-714a03b0c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdd378-b8d9-4243-88bf-e7d5c3960b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename, required_size=(256, 256)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = np.asarray(image)\n",
    "# resize pixels to the model size\n",
    "    image = Image.fromarray(pixels)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = np.asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3283c085-a992-4de4-806a-fd1727174236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_face(dir):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in os.listdir(dir):\n",
    "        path = os.path.join(dir, filename)\n",
    "        face = extract_face(path)\n",
    "        faces.append(face)\n",
    "    return faces\n",
    "\n",
    "def load_dataset(dir, augment=False):\n",
    "    # list for faces and labels\n",
    "    X, y = list(), list()\n",
    "    for subdir in os.listdir(dir):\n",
    "        path = os.path.join(dir, subdir)\n",
    "        faces = load_face(path)\n",
    "        labels = [subdir for i in range(len(faces))]\n",
    "        print(\"loaded %d sample for class: %s\" % (len(faces), subdir))  # print progress\n",
    "        \n",
    "        if augment:\n",
    "          \n",
    "            data_gen = ImageDataGenerator(rotation_range=20, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "            for face in faces:\n",
    "                # Expand the dimensions to make it suitable for the flow() function\n",
    "                face = np.expand_dims(face, axis=0)\n",
    "                # Generate augmented images and labels\n",
    "                for x_batch, y_batch in data_gen.flow(face, [subdir], batch_size=1):\n",
    "                    X.append(x_batch[0])\n",
    "                    y.append(y_batch[0])\n",
    "                    break\n",
    "        else:\n",
    "            X.extend(faces)\n",
    "            y.extend(labels)\n",
    "    \n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4c6e2-d1b5-47b7-a2b6-95cf5a9d50ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "trainX, trainy = load_dataset(r\"C:\\Users\\WELCOME\\Desktop\\jupiter test\\Destination\\train\")\n",
    "print(trainX.shape, trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f56748-e483-460b-abea-a78e2c069587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "testX, testy = load_dataset(r\"C:\\Users\\WELCOME\\Desktop\\jupiter test\\Destination\\test\")\n",
    "print(testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d3e3d-38d1-45e5-b5ff-489201298116",
   "metadata": {},
   "source": [
    "COMPRESS AND SAVE TRAIN AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b8b8b-cd37-4a94-bddb-bf838d9552dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('face.npz', trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091399bd-cc44-4384-a07b-a0c0f0436ce8",
   "metadata": {},
   "source": [
    "LOAD SAVED COMPRESSED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022ffdf-0ec9-4014-b8a9-9329ad496fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"face.npz\")\n",
    "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4f15c-5111-47e2-b211-f049886b3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, valid = train_test_split(trainX, test_size=0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee77074-8c8a-4ce8-ad44-b9c384446207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of image in train dataset : %s\" %(len(trainx)))\n",
    "\n",
    "print(\"number of image in Valid  dataset : %s\" %(len(valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d00bd5-f9ff-4e83-9a54-2438e02ad472",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = train_test_split(trainy, test_size=0.1, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed16933-7c88-42aa-aee2-ac50bc066d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of image in train dataset : %s\" %(len(y_train)))\n",
    "\n",
    "print(\"number of image in Valid dataset : %s\" %(len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69e76c-4078-4691-879c-7d5c91002628",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('extracface.npz', trainx, y_train, valid, y_valid,testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c0888-a859-4907-a94e-6f56e31c11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"extracface.npz\")\n",
    "trainx, y_train, valid, y_valid,testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']\n",
    "print('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c841ea1-d422-40c1-b5ff-554db50f9559",
   "metadata": {},
   "source": [
    "FACE EMBEDDING WITH  FACENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b9446-19bc-47e6-998c-24fbee626f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_facenet import FaceNet\n",
    "facenet_model=FaceNet();\n",
    "print('Loaded model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d8c90-3286-4d29-97fc-963dac4eae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loaded: ', trainx.shape, y_train.shape, valid.shape, y_valid.shape,testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c66ade-a71a-4a1b-8f26-2177047fce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face):\n",
    "    \n",
    "    face = face.astype('float32')\n",
    "\n",
    "    #mean, std = face.mean(), face.std()\n",
    "    #face = (face-mean)/std\n",
    "    \n",
    "    sample = np.expand_dims(face, axis=0)\n",
    "    \n",
    "    yhat = model.embeddings(sample)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e411cf1d-a4bc-4581-8e0d-a6884858d932",
   "metadata": {},
   "source": [
    "CONVERT EACH FACE IN THE TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20701dfe-768e-4f77-91ea-3a5702ea7f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emdTrainX = list()\n",
    "for face in trainx:\n",
    "    emd = get_embedding(facenet_model, face)\n",
    "    emdTrainX.append(emd)\n",
    "emdTrainX = np.asarray(emdTrainX)\n",
    "print(emdTrainX.shape)          \n",
    "embValid = list()\n",
    "for face in valid:\n",
    "    emd = get_embedding(facenet_model,face)\n",
    "    embValid.append(emd)\n",
    "embValid = np.asarray(embValid)\n",
    "print(embValid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a97053-1c60-4c9d-bce8-c504b57f7222",
   "metadata": {},
   "source": [
    "CONVERT EACH FACE IN THE TESTING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f1907-7c30-40ad-8fa0-adee7593fd38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emdTestX = list()\n",
    "for face in testX:\n",
    "    emd = get_embedding(facenet_model, face)\n",
    "    emdTestX.append(emd)\n",
    "emdTestX = np.asarray(emdTestX)\n",
    "print(emdTestX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97083412-ff4f-426d-a287-dfbd4a2a6104",
   "metadata": {},
   "source": [
    "COMPRESS AND SAVE TRAIN AND TESTING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbc81e-a74c-4735-b766-ff8358a03fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('augembeddings.npz', emdTrainX, y_train, embValid, y_valid, emdTestX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd5b24-1814-4839-81e7-01be9b8c1fae",
   "metadata": {},
   "source": [
    "LOAD SAVED COMPRESSED FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad24aa5-8b2b-420a-a47c-ad03260b7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('augembeddings.npz')\n",
    "emdTrainX, y_train, embValid, y_valid, emdTestX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3'], data['arr_4'], data['arr_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20823c-f0a4-40af-ad78-e542876925df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loaded: ', emdTrainX.shape, y_train.shape, embValid.shape, y_valid.shape, emdTestX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf1923-c9af-47e1-a63a-291f4bce989d",
   "metadata": {},
   "source": [
    "LABLE ENCODDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c86f1-23ef-4c04-9ff0-50aaebb35c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "print(\"Dataset: train=%d,validation = %d, test=%d\" % (emdTrainX.shape[0],embValid.shape[0] ,emdTestX.shape[0]))\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "emdTrainX_norm = in_encoder.transform(emdTrainX)\n",
    "embValid_norm = in_encoder.transform(embValid)\n",
    "emdTestX_norm = in_encoder.transform(emdTestX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "encoder_arr = np.append (y_train, 'wangnan')\n",
    "out_encoder.fit(encoder_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef07db-7cc6-43e4-9bed-4cc9e972d4cf",
   "metadata": {},
   "source": [
    "ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924f123-9542-4271-8b43-2c725a83a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy_enc = out_encoder.transform(y_train)\n",
    "y_valid_enc = out_encoder.transform(y_valid)\n",
    "testy_enc = out_encoder.transform(testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe6f93-d87f-4141-adce-d00c07201247",
   "metadata": {},
   "source": [
    "FACE RECOGNITION WITH SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae9150-e3f2-4a50-a48f-78945ccb1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "model = SVC(kernel='poly', probability=True)  # You can choose a different kernel if needed\n",
    "\n",
    "accuracy_scores = cross_val_score(model, emdTrainX, trainy_enc, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Calculate the average accuracy and standard deviation of the accuracy\n",
    "average_accuracy = np.mean(accuracy_scores) * 100\n",
    "std_accuracy = np.std(accuracy_scores) * 100\n",
    "\n",
    "print(\"Cross-Validation Accuracies:\")\n",
    "for i, acc in enumerate(accuracy_scores):\n",
    "    print(f\"Fold {i + 1}: {acc * 100:.2f}%\")\n",
    "\n",
    "print(f'\\nAverage Cross-Validation Accuracy: {average_accuracy:.2f}%')\n",
    "print(f'Standard Deviation of Cross-Validation Accuracy: {std_accuracy:.2f}%')\n",
    "\n",
    "# Train the model on the full training data\n",
    "model.fit(emdTrainX, trainy_enc)\n",
    "\n",
    "# Save the trained model\n",
    "filename = 'Cross_aug.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8dd4d-4641-40f1-b0c3-9bf2831b0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('Cross_aug.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e06e0-5516-4e81-87da-c0549da21e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = loaded_model.predict(emdTestX)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(testy_enc, predictions, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e752b8a-47c0-4040-8849-ff74d52f2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "for i in range(20):\n",
    "    # select a random face from test set\n",
    "    selection = choice([i for i in range(testX.shape[0])]) \n",
    "    random_face = testX[selection]\n",
    "    random_face_emd = emdTestX_norm[selection]\n",
    "    random_face_class = testy_enc[selection]\n",
    "    random_face_name = out_encoder.inverse_transform([random_face_class])\n",
    "    # prediction for the face\n",
    "    samples = np.expand_dims(random_face_emd, axis=0)\n",
    "    yhat_class = loaded_model.predict(samples)\n",
    "    yhat_prob = loaded_model.predict_proba(samples)\n",
    "    class_index = yhat_class[0]\n",
    "    if class_index <= 75:\n",
    "        # get name\n",
    "        class_probability = yhat_prob[0,class_index] * 100\n",
    "        predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "        #print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
    "        #if random_face_name[0] == predict_names[0]:\n",
    "        print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
    "        print('Expected: %s' % random_face_name[0])\n",
    "        # plot face\n",
    "        plt.imshow(random_face)\n",
    "        title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041b15e-cb7c-4976-a2e5-3ddd62368275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_graph(accuracies):\n",
    "    num_folds = len(accuracies)\n",
    "    fold_indices = range(1, num_folds + 1)\n",
    "\n",
    "    plt.bar(fold_indices, accuracies, color='skyblue')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy for each fold in 5-fold cross-validation')\n",
    "    plt.xticks(fold_indices)\n",
    "    plt.ylim(0, 1.0)  # Adjust the y-axis limit based on your accuracy range (usually [0, 1])\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_mean_accuracy_graph(mean_accuracy):\n",
    "    plt.bar(['Mean Accuracy'], [mean_accuracy], color='skyblue')\n",
    "    plt.xlabel('Metric')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Mean Accuracy in 5-fold cross-validation')\n",
    "    plt.ylim(0, 1.0)  # Adjust the y-axis limit based on your accuracy range (usually [0, 1])\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Sample data for accuracy values for each fold (replace this with your actual data)\n",
    "sample_accuracies = [0.98, 0.97, 0.98, 0.96, 0.97]\n",
    "\n",
    "# Sample mean accuracy value (replace this with your actual mean accuracy value)\n",
    "sample_mean_accuracy = np.mean(sample_accuracies)\n",
    "\n",
    "# Plot accuracy for each fold\n",
    "plot_accuracy_graph(sample_accuracies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0abf97c-1fea-4fe7-9692-7ee78dbdf18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_valid = loaded_model.predict(embValid_norm)\n",
    "yhat_test = loaded_model.predict(emdTestX_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afe698-a09b-4ee3-9d0b-954d23f296b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_valid = recall_score(y_valid_enc, yhat_valid, average='weighted')\n",
    "precision_valid = precision_score(y_valid_enc, yhat_valid, average='weighted')\n",
    "f1_valid = f1_score(y_valid_enc, yhat_valid, average='weighted')\n",
    "\n",
    "recall_test = recall_score(testy_enc, yhat_test, average='weighted')\n",
    "precision_test = precision_score(testy_enc, yhat_test, average='weighted')\n",
    "f1_test = f1_score(testy_enc, yhat_test, average='weighted')\n",
    "\n",
    "# Print confusion matrix, accuracy, recall, precision, and F1-score\n",
    "conf_matrix_valid = confusion_matrix(y_valid_enc, yhat_valid)\n",
    "conf_matrix_test = confusion_matrix(testy_enc, yhat_test)\n",
    "\n",
    "print('Validation Set:')\n",
    "print('Accuracy: %.3f' % accuracy_valid)\n",
    "print('Recall: %.3f' % recall_valid)\n",
    "print('Precision: %.3f' % precision_valid)\n",
    "print('F1-score: %.3f' % f1_valid)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_valid)\n",
    "\n",
    "print('------------------------')\n",
    "\n",
    "print('Test Set:')\n",
    "print('Accuracy: %.3f' % accuracy_test)\n",
    "print('Recall: %.3f' % recall_test)\n",
    "print('Precision: %.3f' % precision_test)\n",
    "print('F1-score: %.3f' % f1_test)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7643815b-cf40-42ef-abbe-a013d615bd78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
